{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this has to be changed for the A-Z + 0-9 dataset; otherwise, keyerror.\n",
    "\n",
    "word_dict = {0:'A', 1:'B', 2:'C', 3:'D', 4:'E', 5:'F', 6:'G', 7:'H', 8:'I', 9:'J', \n",
    "             10:'K', 11:'L', 12:'M', 13:'N', 14:'O', 15:'P', 16:'Q', 17:'R', 18:'S', \n",
    "             19:'T', 20:'U', 21:'V', 22:'W', 23:'X', 24:'Y', 25:'Z'}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"-eng-alpha/saved_model/unet-arct-model.h5\"\n",
    "\n",
    "model = load_model(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread(r'_cotet/test-images/download.png') # path to image file\n",
    "img_copy = img.copy()\n",
    "\n",
    "img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB) # converted from BGR to RGB\n",
    "img = cv2.resize(img, (400,440)) # resize the image to our required dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_copy =cv2.GaussianBlur(img_copy, (7,7), 0)\n",
    "img_gray = cv2.cvtColor(img_copy, cv2.COLOR_BGR2GRAY) # to greyscale\n",
    "_, img_thresh = cv2.threshold(img_gray, 100, 255, cv2.THRESH_BINARY_INV) # thresholding because keeps the image smooth without any sort of haz gray colors in the image that could lead to wring predictions\n",
    "\n",
    "img_final = cv2.resize(img_thresh, (28,28)) # resized into the dimensions that the model takes as input\n",
    "img_final = np.reshape(img_final, (1, 28, 28, 1)) # reshaping so that it can be used as model input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_pred = word_dict[np.argmax(model.predict(img_final))]\n",
    "\n",
    "cv2.putText(img, \"IMAGE\", (20,25), cv2.FONT_HERSHEY_SIMPLEX, 0.7, color = (255,0,0))\n",
    "cv2.putText(img, \"Prediction: \" + img_pred, (20,410), cv2.FONT_HERSHEY_SIMPLEX, 1.3, color = (255,0,30))\n",
    "cv2.imshow('External Predicition', img)\n",
    "\n",
    "while (1):\n",
    "    k = cv2.waitKey(1) & 0xFF\n",
    "    if k == 27:\n",
    "        break\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9 (tensorflow)",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
